import streamlit as st
from dotenv import load_dotenv
import os
from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage

# .env ã®èª­ã¿è¾¼ã¿
load_dotenv()

# OpenAI APIã‚­ãƒ¼ã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—
api_key = os.getenv("OPENAI_API_KEY")

# LangChainã®LLMãƒ¢ãƒ‡ãƒ«è¨­å®š
llm = ChatOpenAI(openai_api_key=api_key, model="gpt-3.5-turbo")

# --- Streamlit Webã‚¢ãƒ—ãƒª ---
st.title("ğŸ’¬ LLMã‚¢ãƒ—ãƒª")
st.write("ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã€å°‚é–€å®¶ã®ç¨®é¡ã‚’é¸æŠã™ã‚‹ã¨ã€ãã®å°‚é–€å®¶ã«ãªã‚Šãã£ãŸå›ç­”ãŒè¿”ã£ã¦ãã¾ã™ã€‚")

# ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§å°‚é–€å®¶ã‚’é¸æŠ
role = st.radio("å°‚é–€å®¶ã‚’é¸ã‚“ã§ãã ã•ã„:", ["åŒ»è€…", "æ­´å²å­¦è€…"])

# å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
user_input = st.text_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:")

def get_llm_response(user_text, role):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã¨å°‚é–€å®¶ã®å½¹å‰²ã‚’å—ã‘å–ã‚Šã€LLMã‹ã‚‰ã®å›ç­”ã‚’è¿”ã™"""
    if role == "åŒ»è€…":
        system_message = SystemMessage(content="ã‚ãªãŸã¯å„ªç§€ãªåŒ»è€…ã§ã™ã€‚å°‚é–€çš„ã‹ã¤ã‚ã‹ã‚Šã‚„ã™ãå›ç­”ã—ã¦ãã ã•ã„ã€‚")
    elif role == "æ­´å²å­¦è€…":
        system_message = SystemMessage(content="ã‚ãªãŸã¯çŸ¥è­˜è±Šå¯Œãªæ­´å²å­¦è€…ã§ã™ã€‚æ­´å²çš„ãªèƒŒæ™¯ã‚‚äº¤ãˆã¦èª¬æ˜ã—ã¦ãã ã•ã„ã€‚")
    else:
        system_message = SystemMessage(content="ã‚ãªãŸã¯è¦ªåˆ‡ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚")

    messages = [
        system_message,
        HumanMessage(content=user_text)
    ]

    response = llm.invoke(messages)
    return response.content

# é€ä¿¡ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸã‚‰å‡¦ç†
if st.button("é€ä¿¡"):
    if user_input.strip():
        answer = get_llm_response(user_input, role)
        st.write("### å›ç­”:")
        st.write(answer)
    else:
        st.warning("ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
